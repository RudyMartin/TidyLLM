# TidyLLM MCP (Model Context Protocol) Implementation Guide

## Overview

TidyLLM now includes a fully functional **MCP (Model Context Protocol) server** that provides AI agents with access to enterprise knowledge resources. This implementation has been upgraded from mock data to **real S3 and database integration** with graceful fallback to mock data for development.

## What We Built

### üèóÔ∏è **Complete MCP Stack**

1. **Real Data Source Integration**
   - ‚úÖ **S3KnowledgeSource**: Real AWS S3 integration via UnifiedSessionManager
   - ‚úÖ **DatabaseKnowledgeSource**: Real PostgreSQL integration via UnifiedSessionManager  
   - ‚úÖ **LocalKnowledgeSource**: Local file system integration
   - üîÑ **Graceful Fallback**: Automatic fallback to mock data when AWS/DB unavailable

2. **Enhanced Semantic Search**
   - ‚úÖ **Multi-factor Scoring**: Exact phrase matching, word overlap, metadata matching
   - ‚úÖ **Legal Domain Intelligence**: Boost scoring for legal/contract terminology
   - ‚úÖ **Configurable Thresholds**: Similarity thresholds and result limits

3. **Full MCP Protocol Implementation**
   - ‚úÖ **JSON-RPC over stdio**: Complete MCP specification compliance
   - ‚úÖ **Tool Execution**: search, retrieve, embed, extract, query tools
   - ‚úÖ **Resource Management**: Domain registration and resource listing
   - ‚úÖ **Error Handling**: Comprehensive error responses and logging

4. **Claude Code Integration**
   - ‚úÖ **MCP Configuration**: Ready-to-use `.mcp.json` configuration
   - ‚úÖ **Multiple Server Profiles**: Demo, S3, local, and database configurations
   - ‚úÖ **Command Line Interface**: Full CLI with configuration options

## Quick Start

### 1. **Demo Mode (No AWS Required)**

```bash
# Run with mock data - works immediately
python scripts/run_mcp_server.py

# Or run the comprehensive demo
python scripts/demo_mcp_integration.py
```

### 2. **With Real AWS S3**

```bash
# Configure AWS credentials first
export AWS_ACCESS_KEY_ID=your_key
export AWS_SECRET_ACCESS_KEY=your_secret
export AWS_DEFAULT_REGION=us-east-1

# Run with real S3 integration
python scripts/run_mcp_server.py --s3-bucket your-bucket --s3-prefix contracts/
```

### 3. **With Local Documents**

```bash
# Run with local directory
python scripts/run_mcp_server.py --local-directory ./documents --file-patterns "*.txt,*.md,*.pdf"
```

### 4. **With Database**

```bash
# Configure database connection
export DATABASE_URL=postgresql://user:pass@localhost:5432/tidyllm

# Run with database integration
python scripts/run_mcp_server.py --db-table legal_documents --db-schema public
```

## Architecture

### **Data Flow Architecture**

```
Claude Code ‚Üí MCP Protocol ‚Üí TidyLLM Knowledge Server ‚Üí Multiple Data Sources
                ‚Üì                      ‚Üì                         ‚Üì
         JSON-RPC over stdio    KnowledgeMCPServer        S3 / Database / Local
                ‚Üì                      ‚Üì                         ‚Üì
         Tool calls (search)    Enhanced Search Engine    UnifiedSessionManager
                ‚Üì                      ‚Üì                         ‚Üì
         Structured Results     Semantic Matching         Real Data + Fallback
```

### **Integration with Gateways**

The MCP server integrates seamlessly with TidyLLM's gateway architecture:

```
Legal Document Analysis Workflow:
CorporateLLMGateway ‚Üí AIProcessingGateway ‚Üí WorkflowOptimizerGateway
        ‚Üì                     ‚Üì                        ‚Üì
   Access Control      Multi-Model AI           Workflow Intelligence
        ‚Üì                     ‚Üì                        ‚Üì
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ KnowledgeMCPServer ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
                    Context & Knowledge
```

## Real-World Usage Example

### **Legal Contract Analysis Scenario**

When processing a legal contract through TidyLLM:

1. **User Request**: "Analyze this contract for termination clauses and compliance issues"

2. **Gateway Flow**:
   - `CorporateLLMGateway`: Validates user permissions for legal document access
   - `AIProcessingGateway`: Routes to appropriate AI models for contract analysis
   - `WorkflowOptimizerGateway`: Optimizes the document review workflow

3. **Knowledge Integration**: Each gateway can query the MCP server:
   ```python
   # Search for relevant legal precedents
   results = mcp_client.call_tool("search", {
       "query": "contract termination clauses",
       "domain": "legal-contracts", 
       "similarity_threshold": 0.8
   })
   ```

4. **Enhanced AI Response**: AI models receive enriched context from:
   - S3-stored legal precedents and clause libraries
   - Database-backed compliance requirements and policies
   - Local technical documentation for processing workflows

## Configuration Files

### **Claude Code Integration (`.mcp.json`)**

The project includes a complete `.mcp.json` file with multiple server configurations:

- **`tidyllm-knowledge`**: Demo server with mock data
- **`tidyllm-s3-legal`**: Real S3 legal documents
- **`tidyllm-local-docs`**: Local document processing  
- **`tidyllm-database`**: Database-backed knowledge

### **AWS Configuration Check**

Use the diagnostic script to verify AWS setup:

```bash
python scripts/check_aws_config.py
```

This will check:
- Environment variables
- `~/.aws/credentials` file
- `~/.aws/config` file
- Boto3 connectivity
- UnifiedSessionManager integration

## Advanced Features

### **1. Multi-Source Search**

Search across all registered domains:

```python
# Search legal contracts in S3
s3_results = server.handle_mcp_tool_call("search", {
    "query": "termination procedures",
    "domain": "legal-s3",
    "max_results": 5
})

# Search policies in database  
db_results = server.handle_mcp_tool_call("search", {
    "query": "compliance requirements", 
    "domain": "legal-db",
    "max_results": 5
})
```

### **2. Enhanced Semantic Scoring**

The search engine uses multi-factor scoring:

- **Exact Phrase Matching** (0.8-0.9 weight)
- **Word Overlap Scoring** (0.5-0.7 weight)  
- **Metadata Matching** (0.4 weight)
- **Legal Term Boosting** (0.3 additional weight)

### **3. Real Database Integration**

Connects to PostgreSQL via UnifiedSessionManager:

```sql
-- Expected table structure
CREATE TABLE legal_documents (
    id VARCHAR PRIMARY KEY,
    title VARCHAR,
    content TEXT,
    metadata JSONB,
    created_at TIMESTAMP,
    updated_at TIMESTAMP
);
```

## Troubleshooting

### **AWS Connection Issues**

**Problem**: "AccessDenied" or "Unable to locate credentials"
**Solution**: 
1. Run `python scripts/check_aws_config.py` to diagnose
2. Set environment variables or create `~/.aws/credentials`
3. The system gracefully falls back to mock data if AWS unavailable

### **Import Path Issues**

**Problem**: "UnifiedSessionManager not available"
**Solution**: The code now handles both relative and absolute imports automatically

### **Database Connection Issues**

**Problem**: Database connection failures
**Solution**: System automatically falls back to mock database data

## Testing

### **Comprehensive Testing**

```bash
# Run full integration demo
python scripts/demo_mcp_integration.py

# Test specific configurations
python scripts/run_mcp_server.py --help

# Check AWS configuration
python scripts/check_aws_config.py
```

### **MCP Protocol Testing**

The system includes complete MCP protocol testing with:
- Initialize requests
- Tools list and execution
- Resource management
- Error handling
- Client-server communication

## Key Benefits

### **For Developers**

1. **No Setup Required**: Works immediately with mock data
2. **Real Integration**: Seamless S3 and database connectivity when available
3. **MCP Compliance**: Full Model Context Protocol implementation
4. **Extensible**: Easy to add new knowledge sources

### **For Enterprise Users**

1. **Security**: All requests go through corporate gateways
2. **Compliance**: Full audit trails and access control
3. **Scalability**: Handles large document repositories
4. **Integration**: Works with existing enterprise storage systems

### **For AI Agents**

1. **Rich Context**: Access to structured enterprise knowledge
2. **Semantic Search**: Intelligent document matching
3. **Multi-Source**: Aggregate information from multiple sources
4. **Real-Time**: Live access to current document repositories

## Summary

‚úÖ **MCP Implementation Complete**: Full JSON-RPC over stdio protocol
‚úÖ **Real Data Integration**: S3, PostgreSQL, and local file system
‚úÖ **Enhanced Search**: Multi-factor semantic scoring
‚úÖ **Gateway Integration**: Works with TidyLLM's enterprise architecture
‚úÖ **Claude Code Ready**: Complete `.mcp.json` configuration
‚úÖ **Production Grade**: Graceful fallbacks and error handling
‚úÖ **Comprehensive Testing**: Full test suite and diagnostic tools

The TidyLLM MCP server transforms from a prototype with mock data into a **production-ready enterprise knowledge resource provider** that AI agents can use to access real company data through a standardized protocol.